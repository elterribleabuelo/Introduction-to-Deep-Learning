{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "mnist_with_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRsFPEZFQ439",
        "colab_type": "text"
      },
      "source": [
        "# Conectando Colab con drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlGD8a_fQ7wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feca81ed-13c3-4760-fea5-90f5624ee77b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D38BflaRGv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Programacion/Python/Machine Learning avanzado/1.Introduccion al Deep Learning/Semana2')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5lrf1ibK4Tc",
        "colab_type": "text"
      },
      "source": [
        "# MNIST digits classification with Keras\n",
        "\n",
        "We don't expect you to code anything here because you've already solved it with TensorFlow.\n",
        "\n",
        "But you can appreciate how simpler it is with Keras.\n",
        "\n",
        "We'll be happy if you play around with the architecture though, there're some tips at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l764oiZOK4Tg",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"images/mnist_sample.png\" style=\"width:30%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqDifjWUK4Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e69ce7a6-db9c-4e6a-c1b8-632a56dd6f5a"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)\n",
        "import keras\n",
        "print(\"We are using Keras\", keras.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/Programacion/Python/Machine Learning avanzado/1.Introduccion al Deep Learning/Semana2\")\n",
        "import keras_utils\n",
        "#from keras_utils import reset_tf_session"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 2.3.0\n",
            "We are using Keras 2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5zC1pcEK4Tz",
        "colab_type": "text"
      },
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWlvkGliK4T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import preprocessed_mnist\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset_from_file()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wihTe-txK4UI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "c174f1f2-cdff-4582-f88e-ffdea5e39b7b"
      },
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [shape (50000, 28, 28)] sample patch:\n",
            " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
            " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
            " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
            " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
            " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
            "A closeup of a sample patch:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "And the whole sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOdUlEQVR4nO3dfayU5ZnH8d8lLb4AEpAjQXvicRETtYnQTMgmJQ2bug3oH0h8CUQJa4g0BJSa+haMqTGayLotSlyJsBBw7dI0FCN/mLVKGrF/2DgClRezq4sH4QQ5hwip1Wh5ufaP89gc8Tz3HGaemWfg+n6Sycw819znuTL645l57pm5zd0F4Nx3XtkNAGgNwg4EQdiBIAg7EARhB4L4Tit3Nm7cOO/q6mrlLoFQuru7deTIERus1lDYzWyGpGclDZP0H+7+VOrxXV1dqlarjewSQEKlUsmt1f0y3syGSfp3STMlXStprpldW+/fA9BcjbxnnyrpQ3ff5+5/k/QbSbOKaQtA0RoJ++WSDgy4fzDb9g1mttDMqmZW7evra2B3ABrR9LPx7r7a3SvuXuno6Gj27gDkaCTsPZI6B9z/XrYNQBtqJOzvSJpkZlea2XBJcyRtKaYtAEWre+rN3U+Y2RJJr6l/6m2du+8prDMAhWpont3dX5X0akG9AGgiPi4LBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBAtXbIZ554DBw4k688++2xubcWKFcmx9913X7K+dOnSZL2zszNZj4YjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTw7knp6epL1KVOmJOvHjh3LrZlZcuwzzzyTrG/YsCFZ7+vrS9ajaSjsZtYt6TNJJyWdcPdKEU0BKF4RR/Z/cvcjBfwdAE3Ee3YgiEbD7pJ+b2bvmtnCwR5gZgvNrGpmVd5DAeVpNOzT3P0HkmZKWmxmPzr9Ae6+2t0r7l7p6OhocHcA6tVQ2N29J7vulfSypKlFNAWgeHWH3cxGmNmor29L+omk3UU1BqBYjZyNHy/p5Wyu9DuS/svd/7uQrtAy+/fvT9anT5+erB89ejRZT82ljx49Ojn2/PPPT9Z7e3uT9X379uXWrrjiiuTYYcOGJetno7rD7u77JF1fYC8AmoipNyAIwg4EQdiBIAg7EARhB4LgK67ngOPHj+fWak2tzZgxI1mv9VPRjZg8eXKy/uSTTybr06ZNS9YnTZqUW1u9enVy7IIFC5L1sxFHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2c8ADDzyQW3vuueda2MmZefPNN5P1zz//PFmfPXt2sr558+bc2o4dO5Jjz0Uc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZzwK1vlP+0ksv5dbcvaF915rLvuWWW5L1O++8M7fW2dmZHHvNNdck6w899FCyvmnTptxao8/L2YgjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EYa2cb6xUKl6tVlu2v7NFT09Psn799enFco8dO1b3vu+4445kfc2aNcn63r17k/Xt27fn1ubMmZMce9FFFyXrtaSWXR4xYkRy7J49e5L1Wp8RKEulUlG1Wh10neyaR3YzW2dmvWa2e8C2sWb2upl9kF2PKbJhAMUbysv49ZJOXzbkYUlb3X2SpK3ZfQBtrGbY3X2bpE9P2zxL0obs9gZJNxfcF4CC1XuCbry7H8pufyJpfN4DzWyhmVXNrNrX11fn7gA0quGz8d5/hi/3LJ+7r3b3irtXOjo6Gt0dgDrVG/bDZjZBkrLr3uJaAtAM9YZ9i6T52e35kl4pph0AzVLz++xmtlHSdEnjzOygpF9IekrSb81sgaT9km5vZpNnuyNHjiTry5cvT9aPHj2arI8fn3vKRFdeeWVy7KJFi5L14cOHJ+u11livVS/LF198kaw//fTTyfrKlSuLbKclaobd3efmlH5ccC8AmoiPywJBEHYgCMIOBEHYgSAIOxAEPyVdgBMnTiTr999/f7Ke+iloSRo9enSy/tprr+XWrrrqquTY48ePJ+tRffTRR2W3UDiO7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBPPsBfj444+T9Vrz6LW8/fbbyfrVV19d99++8MIL6x6LswtHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2AixevDhZr7Us9uzZs5P1RubRIzt16lRu7bzz0se5Vi5l3ioc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZh2jHjh25tW3btiXHmlmyftttt9XVE9JSc+m1/ptUKpWi2yldzSO7ma0zs14z2z1g22Nm1mNmO7PLjc1tE0CjhvIyfr2kGYNsX+Huk7PLq8W2BaBoNcPu7tskfdqCXgA0USMn6JaY2XvZy/wxeQ8ys4VmVjWzal9fXwO7A9CIesO+StJESZMlHZL0y7wHuvtqd6+4e6Wjo6PO3QFoVF1hd/fD7n7S3U9JWiNparFtAShaXWE3swkD7s6WtDvvsQDaQ815djPbKGm6pHFmdlDSLyRNN7PJklxSt6SfNrHHtvDll1/m1r766qvk2MsuuyxZv+mmm+rq6VxXa937lStX1v23b7311mR92bJldf/tdlUz7O4+d5DNa5vQC4Am4uOyQBCEHQiCsANBEHYgCMIOBMFXXFvgggsuSNZHjhzZok7aS62ptVWrViXrDz74YLLe1dWVW3vkkUeSY4cPH56sn404sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMyzt8C8efPKbqE0PT09ubXly5cnxz7//PPJ+l133ZWsr1mzJlmPhiM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPPsQuXtdNUlav359sv7oo4/W01Jb2LhxY7J+zz335NaOHj2aHHvvvfcm6ytWrEjW8U0c2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZh8jM6qpJ0sGDB5P1xx9/PFlfsGBBsj5q1Kjc2p49e5JjX3jhhWT9rbfeSta7u7uT9YkTJ+bW5syZkxxba54dZ6bmkd3MOs3sD2a218z2mNnSbPtYM3vdzD7Irsc0v10A9RrKy/gTkn7u7tdK+kdJi83sWkkPS9rq7pMkbc3uA2hTNcPu7ofcfXt2+zNJ70u6XNIsSRuyh22QdHOzmgTQuDM6QWdmXZKmSPqTpPHufigrfSJpfM6YhWZWNbNqX19fA60CaMSQw25mIyX9TtLP3P0vA2ve/02QQb8N4u6r3b3i7pWOjo6GmgVQvyGF3cy+q/6g/9rdN2ebD5vZhKw+QVJvc1oEUISaU2/WP6+0VtL77v6rAaUtkuZLeiq7fqUpHZ4DTp48mazXmnpbu3Ztsj527Njc2q5du5JjGzVz5sxkfcaMGbm1JUuWFN0OEoYyz/5DSfMk7TKzndm2ZeoP+W/NbIGk/ZJub06LAIpQM+zu/kdJeZ8a+XGx7QBoFj4uCwRB2IEgCDsQBGEHgiDsQBB8xXWIrrvuutzaDTfckBz7xhtvNLTvWl+RTS2LXMull16arC9atChZP5t/BjsajuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATz7EN08cUX59Y2bdqUHPviiy8m6838yeQnnngiWb/77ruT9UsuuaTIdlAijuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EIT1L+bSGpVKxavVasv2B0RTqVRUrVYH/TVojuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EETNsJtZp5n9wcz2mtkeM1uabX/MzHrMbGd2ubH57QKo11B+vOKEpJ+7+3YzGyXpXTN7PautcPd/a157AIoylPXZD0k6lN3+zMzel3R5sxsDUKwzes9uZl2Spkj6U7ZpiZm9Z2brzGxMzpiFZlY1s2pfX19DzQKo35DDbmYjJf1O0s/c/S+SVkmaKGmy+o/8vxxsnLuvdveKu1c6OjoKaBlAPYYUdjP7rvqD/mt33yxJ7n7Y3U+6+ylJayRNbV6bABo1lLPxJmmtpPfd/VcDtk8Y8LDZknYX3x6AogzlbPwPJc2TtMvMdmbblkmaa2aTJbmkbkk/bUqHAAoxlLPxf5Q02PdjXy2+HQDNwifogCAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQbR0yWYz65O0f8CmcZKOtKyBM9OuvbVrXxK91avI3q5w90F//62lYf/Wzs2q7l4prYGEdu2tXfuS6K1ereqNl/FAEIQdCKLssK8uef8p7dpbu/Yl0Vu9WtJbqe/ZAbRO2Ud2AC1C2IEgSgm7mc0ws/8xsw/N7OEyeshjZt1mtitbhrpaci/rzKzXzHYP2DbWzF43sw+y60HX2Cupt7ZYxjuxzHipz13Zy5+3/D27mQ2T9L+S/lnSQUnvSJrr7ntb2kgOM+uWVHH30j+AYWY/kvRXSS+6+/ezbf8q6VN3fyr7h3KMuz/UJr09JumvZS/jna1WNGHgMuOSbpb0LyrxuUv0dbta8LyVcWSfKulDd9/n7n+T9BtJs0roo+25+zZJn562eZakDdntDer/n6XlcnprC+5+yN23Z7c/k/T1MuOlPneJvlqijLBfLunAgPsH1V7rvbuk35vZu2a2sOxmBjHe3Q9ltz+RNL7MZgZRcxnvVjptmfG2ee7qWf68UZyg+7Zp7v4DSTMlLc5errYl738P1k5zp0NaxrtVBllm/O/KfO7qXf68UWWEvUdS54D738u2tQV378mueyW9rPZbivrw1yvoZte9Jffzd+20jPdgy4yrDZ67Mpc/LyPs70iaZGZXmtlwSXMkbSmhj28xsxHZiROZ2QhJP1H7LUW9RdL87PZ8Sa+U2Ms3tMsy3nnLjKvk56705c/dveUXSTeq/4z8/0l6pIwecvr6B0l/zi57yu5N0kb1v6w7rv5zGwskXSJpq6QPJL0haWwb9fafknZJek/9wZpQUm/T1P8S/T1JO7PLjWU/d4m+WvK88XFZIAhO0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8PJdJc1jCDmVwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train [shape (50000,)] 10 samples:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5nULMiFK4UY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f2a5a78-5552-4cc4-c73f-b7d11126f56e"
      },
      "source": [
        "# flatten images\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXh2Fez3K4Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fefa6a54-e251-47b8-eec0-441833176a40"
      },
      "source": [
        "# one-hot encode the target\n",
        "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFkyOVmOK4U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building a model with keras\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "# we still need to clear a graph though\n",
        "#s = reset_tf_session()\n",
        "\n",
        "model = Sequential()  # it is a feed-forward network without loops like in RNN\n",
        "model.add(Dense(256,input_shape=(784,))) # the first layer must specify the input shape (replacing placeholders)\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(256)\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ct76Z8uK4VF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "12b0d058-651b-4f9e-a135-e6afc79daaec"
      },
      "source": [
        "# you can look at all layers and parameter count\n",
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 269,322\n",
            "Trainable params: 269,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHfSXb2mK4VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we \"compile\" the model specifying the loss and optimizer\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # this is our cross-entropy\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EygG6E8ZK4Vf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "461fda73-0ca1-43f0-88e9-e749851b465a"
      },
      "source": [
        "# and now we can fit the model with model.fit()\n",
        "# and we don't have to write loops and batching manually as in TensorFlow\n",
        "model.fit(\n",
        "    X_train_flat, \n",
        "    y_train_oh,\n",
        "    batch_size=512, \n",
        "    epochs=40,\n",
        "    validation_data=(X_val_flat, y_val_oh),\n",
        "    callbacks=early_stopping_cb,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 9.9692 - accuracy: 0.5560 - val_loss: 2.5312 - val_accuracy: 0.7169\n",
            "Epoch 2/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7843 - accuracy: 0.6963 - val_loss: 1.4526 - val_accuracy: 0.7336\n",
            "Epoch 3/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.3441 - accuracy: 0.7652 - val_loss: 1.2211 - val_accuracy: 0.8205\n",
            "Epoch 4/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.1664 - accuracy: 0.8150 - val_loss: 1.0704 - val_accuracy: 0.8615\n",
            "Epoch 5/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.0435 - accuracy: 0.8483 - val_loss: 0.9724 - val_accuracy: 0.8660\n",
            "Epoch 6/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.9530 - accuracy: 0.8642 - val_loss: 0.8939 - val_accuracy: 0.8774\n",
            "Epoch 7/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.8852 - accuracy: 0.8737 - val_loss: 0.8306 - val_accuracy: 0.8940\n",
            "Epoch 8/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.8269 - accuracy: 0.8831 - val_loss: 0.7856 - val_accuracy: 0.8969\n",
            "Epoch 9/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.7829 - accuracy: 0.8879 - val_loss: 0.7366 - val_accuracy: 0.8997\n",
            "Epoch 10/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.7439 - accuracy: 0.8932 - val_loss: 0.7014 - val_accuracy: 0.9055\n",
            "Epoch 11/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.7128 - accuracy: 0.8961 - val_loss: 0.6799 - val_accuracy: 0.9064\n",
            "Epoch 12/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.6830 - accuracy: 0.8999 - val_loss: 0.6482 - val_accuracy: 0.9090\n",
            "Epoch 13/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.6585 - accuracy: 0.9027 - val_loss: 0.6242 - val_accuracy: 0.9127\n",
            "Epoch 14/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.6380 - accuracy: 0.9037 - val_loss: 0.6097 - val_accuracy: 0.9121\n",
            "Epoch 15/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.6175 - accuracy: 0.9082 - val_loss: 0.5883 - val_accuracy: 0.9138\n",
            "Epoch 16/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.6005 - accuracy: 0.9081 - val_loss: 0.5757 - val_accuracy: 0.9149\n",
            "Epoch 17/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.5843 - accuracy: 0.9095 - val_loss: 0.5600 - val_accuracy: 0.9206\n",
            "Epoch 18/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.5697 - accuracy: 0.9115 - val_loss: 0.5446 - val_accuracy: 0.9222\n",
            "Epoch 19/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.5578 - accuracy: 0.9135 - val_loss: 0.5328 - val_accuracy: 0.9223\n",
            "Epoch 20/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.5461 - accuracy: 0.9147 - val_loss: 0.5309 - val_accuracy: 0.9192\n",
            "Epoch 21/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.5346 - accuracy: 0.9169 - val_loss: 0.5129 - val_accuracy: 0.9209\n",
            "Epoch 22/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.5226 - accuracy: 0.9168 - val_loss: 0.5033 - val_accuracy: 0.9224\n",
            "Epoch 23/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.5120 - accuracy: 0.9204 - val_loss: 0.4968 - val_accuracy: 0.9216\n",
            "Epoch 24/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.5036 - accuracy: 0.9202 - val_loss: 0.4848 - val_accuracy: 0.9254\n",
            "Epoch 25/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4946 - accuracy: 0.9210 - val_loss: 0.4772 - val_accuracy: 0.9248\n",
            "Epoch 26/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4858 - accuracy: 0.9223 - val_loss: 0.4652 - val_accuracy: 0.9272\n",
            "Epoch 27/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4790 - accuracy: 0.9236 - val_loss: 0.4697 - val_accuracy: 0.9264\n",
            "Epoch 28/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.4752 - accuracy: 0.9231 - val_loss: 0.4555 - val_accuracy: 0.9289\n",
            "Epoch 29/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4659 - accuracy: 0.9261 - val_loss: 0.4545 - val_accuracy: 0.9298\n",
            "Epoch 30/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4573 - accuracy: 0.9274 - val_loss: 0.4442 - val_accuracy: 0.9297\n",
            "Epoch 31/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4526 - accuracy: 0.9280 - val_loss: 0.4456 - val_accuracy: 0.9274\n",
            "Epoch 32/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4466 - accuracy: 0.9293 - val_loss: 0.4374 - val_accuracy: 0.9310\n",
            "Epoch 33/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 0.4379 - accuracy: 0.9299 - val_loss: 0.4265 - val_accuracy: 0.9343\n",
            "Epoch 34/40\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 0.4331 - accuracy: 0.9307 - val_loss: 0.4204 - val_accuracy: 0.9340\n",
            "Epoch 35/40\n",
            "98/98 [==============================] - 2s 22ms/step - loss: 0.4308 - accuracy: 0.9318 - val_loss: 0.4229 - val_accuracy: 0.9318\n",
            "Epoch 36/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 0.4234 - accuracy: 0.9317 - val_loss: 0.4144 - val_accuracy: 0.9345\n",
            "Epoch 37/40\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.4185 - accuracy: 0.9335 - val_loss: 0.4090 - val_accuracy: 0.9328\n",
            "Epoch 38/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.4124 - accuracy: 0.9342 - val_loss: 0.4099 - val_accuracy: 0.9323\n",
            "Epoch 39/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.4093 - accuracy: 0.9348 - val_loss: 0.4006 - val_accuracy: 0.9365\n",
            "Epoch 40/40\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.4039 - accuracy: 0.9358 - val_loss: 0.3913 - val_accuracy: 0.9387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9ae6118780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li4eKYC5K4Vq",
        "colab_type": "text"
      },
      "source": [
        "# Here're the notes for those who want to play around here\n",
        "\n",
        "Here are some tips on what you could do:\n",
        "\n",
        " * __Network size__\n",
        "   * More neurons, \n",
        "   * More layers, ([docs](https://keras.io/))\n",
        "\n",
        "   * Other nonlinearities in the hidden layers\n",
        "     * tanh, relu, leaky relu, etc\n",
        "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
        "\n",
        "\n",
        " * __Early Stopping__\n",
        "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
        "   * Some networks converge over 5 epochs, others - over 500.\n",
        "   * Way to go: stop when validation score is 10 iterations past maximum\n",
        "     \n",
        "\n",
        " * __Faster optimization__\n",
        "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
        "     * Converge faster and sometimes reach better optima\n",
        "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
        "\n",
        "\n",
        " * __Regularize__ to prevent overfitting\n",
        "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
        "     * Can be done manually or via - https://keras.io/regularizers/\n",
        "   \n",
        "   \n",
        " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
        "   * https://keras.io/preprocessing/image/\n",
        "   * Zoom-in+slice = move\n",
        "   * Rotate+zoom(to remove black stripes)\n",
        "   * any other perturbations\n",
        "   * Simple way to do that (if you have PIL/Image): \n",
        "     * ```from scipy.misc import imrotate,imresize```\n",
        "     * and a few slicing\n",
        "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qair39kB7iEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kernel_regularizer : Regularizador para aplicar una penalización en el núcleo o pesos de la capa\n",
        "# bias_regularizer : Regularizador para aplicar una penalización en el sesgo o bias de la capa\n",
        "# activity_regularizer : Regularizador para aplicar una penalización en la salida de la capa\n",
        "# https://keras.io/api/layers/initializers/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQfK67kK4Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building a model with keras\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "# we still need to clear a graph though\n",
        "#s = reset_tf_session()\n",
        "\n",
        "model = Sequential()  # it is a feed-forward network without loops like in RNN\n",
        "initializer = tf.keras.initializers.Zeros\n",
        "model.add(Dense(256,\n",
        "                kernel_initializer=initializer, # iniciamlizamos los pesos con unos\n",
        "                input_shape=(784,))) # the first layer must specify the input shape (replacing placeholders)\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10,kernel_regularizer=tf.keras.regularizers.l2(0.10),  # Penalizacion l1 con una fuerza de regularizacion 0.01\n",
        "          activity_regularizer=tf.keras.regularizers.l2(0.10) # Penalización l2 con una fuerza de regularizacion 0.01\n",
        "          ))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcitXK-6doh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bc8b4cb4-fda3-4e5c-a7c6-95c61e30d1aa"
      },
      "source": [
        "# you can look at all layers and parameter count\n",
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 269,322\n",
            "Trainable params: 269,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmH5mMIm6hRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we \"compile\" the model specifying the loss and optimizer\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # this is our cross-entropy\n",
        "    optimizer='rmsprop',\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzcFnTjt6mLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generando el callback \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_cb = EarlyStopping(patience=10,# patience:cuantas iteraciones voy a esperar que baje mi perdida para detener el algoritmo\n",
        "                                  verbose=1)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BzOZPLV6uj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5ce6703-96ec-4261-e6fc-a3d8d755c574"
      },
      "source": [
        "# and now we can fit the model with model.fit()\n",
        "# and we don't have to write loops and batching manually as in TensorFlow\n",
        "model.fit(\n",
        "    X_train_flat, \n",
        "    y_train_oh,\n",
        "    batch_size=512, \n",
        "    epochs=40,\n",
        "    validation_data=(X_val_flat, y_val_oh),\n",
        "    callbacks=early_stopping_cb,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "98/98 [==============================] - 2s 22ms/step - loss: 2.8572 - accuracy: 0.7821 - val_loss: 2.0604 - val_accuracy: 0.8681\n",
            "Epoch 2/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.7652 - accuracy: 0.8767 - val_loss: 1.5486 - val_accuracy: 0.9004\n",
            "Epoch 3/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.4956 - accuracy: 0.9011 - val_loss: 1.4313 - val_accuracy: 0.9178\n",
            "Epoch 4/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.4181 - accuracy: 0.9166 - val_loss: 1.3771 - val_accuracy: 0.9301\n",
            "Epoch 5/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.3778 - accuracy: 0.9282 - val_loss: 1.3530 - val_accuracy: 0.9399\n",
            "Epoch 6/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.3517 - accuracy: 0.9376 - val_loss: 1.3359 - val_accuracy: 0.9447\n",
            "Epoch 7/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.3325 - accuracy: 0.9446 - val_loss: 1.3258 - val_accuracy: 0.9484\n",
            "Epoch 8/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.3178 - accuracy: 0.9511 - val_loss: 1.3034 - val_accuracy: 0.9577\n",
            "Epoch 9/40\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 1.3064 - accuracy: 0.9565 - val_loss: 1.2957 - val_accuracy: 0.9609\n",
            "Epoch 10/40\n",
            "98/98 [==============================] - 2s 22ms/step - loss: 1.2970 - accuracy: 0.9605 - val_loss: 1.2899 - val_accuracy: 0.9632\n",
            "Epoch 11/40\n",
            "98/98 [==============================] - 2s 21ms/step - loss: 1.2887 - accuracy: 0.9651 - val_loss: 1.2874 - val_accuracy: 0.9638\n",
            "Epoch 12/40\n",
            "98/98 [==============================] - 2s 21ms/step - loss: 1.2817 - accuracy: 0.9687 - val_loss: 1.2829 - val_accuracy: 0.9652\n",
            "Epoch 13/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2755 - accuracy: 0.9712 - val_loss: 1.2745 - val_accuracy: 0.9700\n",
            "Epoch 14/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2705 - accuracy: 0.9738 - val_loss: 1.2734 - val_accuracy: 0.9706\n",
            "Epoch 15/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2661 - accuracy: 0.9756 - val_loss: 1.2777 - val_accuracy: 0.9711\n",
            "Epoch 16/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2623 - accuracy: 0.9776 - val_loss: 1.2660 - val_accuracy: 0.9727\n",
            "Epoch 17/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2584 - accuracy: 0.9799 - val_loss: 1.2631 - val_accuracy: 0.9736\n",
            "Epoch 18/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2549 - accuracy: 0.9807 - val_loss: 1.2637 - val_accuracy: 0.9748\n",
            "Epoch 19/40\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 1.2524 - accuracy: 0.9825 - val_loss: 1.2621 - val_accuracy: 0.9753\n",
            "Epoch 20/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2493 - accuracy: 0.9840 - val_loss: 1.2589 - val_accuracy: 0.9760\n",
            "Epoch 21/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2469 - accuracy: 0.9851 - val_loss: 1.2601 - val_accuracy: 0.9760\n",
            "Epoch 22/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2446 - accuracy: 0.9862 - val_loss: 1.2619 - val_accuracy: 0.9767\n",
            "Epoch 23/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2422 - accuracy: 0.9872 - val_loss: 1.2570 - val_accuracy: 0.9768\n",
            "Epoch 24/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2406 - accuracy: 0.9880 - val_loss: 1.2546 - val_accuracy: 0.9782\n",
            "Epoch 25/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2390 - accuracy: 0.9887 - val_loss: 1.2529 - val_accuracy: 0.9773\n",
            "Epoch 26/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2369 - accuracy: 0.9892 - val_loss: 1.2581 - val_accuracy: 0.9765\n",
            "Epoch 27/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2354 - accuracy: 0.9899 - val_loss: 1.2531 - val_accuracy: 0.9774\n",
            "Epoch 28/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2340 - accuracy: 0.9904 - val_loss: 1.2525 - val_accuracy: 0.9784\n",
            "Epoch 29/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2324 - accuracy: 0.9912 - val_loss: 1.2546 - val_accuracy: 0.9784\n",
            "Epoch 30/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2312 - accuracy: 0.9916 - val_loss: 1.2472 - val_accuracy: 0.9798\n",
            "Epoch 31/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2298 - accuracy: 0.9921 - val_loss: 1.2527 - val_accuracy: 0.9780\n",
            "Epoch 32/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2286 - accuracy: 0.9926 - val_loss: 1.2522 - val_accuracy: 0.9777\n",
            "Epoch 33/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2274 - accuracy: 0.9930 - val_loss: 1.2490 - val_accuracy: 0.9788\n",
            "Epoch 34/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2263 - accuracy: 0.9932 - val_loss: 1.2486 - val_accuracy: 0.9795\n",
            "Epoch 35/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2253 - accuracy: 0.9939 - val_loss: 1.2513 - val_accuracy: 0.9792\n",
            "Epoch 36/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2242 - accuracy: 0.9944 - val_loss: 1.2479 - val_accuracy: 0.9794\n",
            "Epoch 37/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2232 - accuracy: 0.9946 - val_loss: 1.2510 - val_accuracy: 0.9793\n",
            "Epoch 38/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2227 - accuracy: 0.9949 - val_loss: 1.2441 - val_accuracy: 0.9802\n",
            "Epoch 39/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2215 - accuracy: 0.9953 - val_loss: 1.2463 - val_accuracy: 0.9790\n",
            "Epoch 40/40\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.2206 - accuracy: 0.9958 - val_loss: 1.2504 - val_accuracy: 0.9789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9ae95da6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMkacvKA-AmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}